{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1314,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.09475789219141006,
      "learning_rate": 1.8560606060606062e-06,
      "logits/chosen": -4.905604362487793,
      "logits/rejected": -5.304989814758301,
      "logps/chosen": -315.621826171875,
      "logps/rejected": -72.5701904296875,
      "loss": 0.121,
      "rewards/accuracies": 0.9474999904632568,
      "rewards/chosen": 18.56020164489746,
      "rewards/margins": 15.371883392333984,
      "rewards/rejected": 3.188316822052002,
      "step": 50
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.04997605085372925,
      "learning_rate": 3.7500000000000005e-06,
      "logits/chosen": -4.850740432739258,
      "logits/rejected": -5.279986381530762,
      "logps/chosen": -305.6611633300781,
      "logps/rejected": -69.45881652832031,
      "loss": 0.1096,
      "rewards/accuracies": 0.9599999785423279,
      "rewards/chosen": 19.092586517333984,
      "rewards/margins": 16.02800941467285,
      "rewards/rejected": 3.0645785331726074,
      "step": 100
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.16091154515743256,
      "learning_rate": 4.997448481273023e-06,
      "logits/chosen": -4.878270626068115,
      "logits/rejected": -5.318150043487549,
      "logps/chosen": -295.86981201171875,
      "logps/rejected": -79.39643859863281,
      "loss": 0.0852,
      "rewards/accuracies": 0.9724999666213989,
      "rewards/chosen": 18.02398109436035,
      "rewards/margins": 15.132747650146484,
      "rewards/rejected": 2.891234874725342,
      "step": 150
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.8915807604789734,
      "learning_rate": 4.960465483108446e-06,
      "logits/chosen": -4.884103775024414,
      "logits/rejected": -5.332185745239258,
      "logps/chosen": -309.72625732421875,
      "logps/rejected": -75.49144744873047,
      "loss": 0.0338,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 18.336151123046875,
      "rewards/margins": 15.988290786743164,
      "rewards/rejected": 2.3478622436523438,
      "step": 200
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.10632428526878357,
      "learning_rate": 4.880093166703595e-06,
      "logits/chosen": -4.7679643630981445,
      "logits/rejected": -5.291412353515625,
      "logps/chosen": -322.3443603515625,
      "logps/rejected": -92.43909454345703,
      "loss": 0.0267,
      "rewards/accuracies": 0.9874999523162842,
      "rewards/chosen": 19.44961929321289,
      "rewards/margins": 17.188785552978516,
      "rewards/rejected": 2.260833740234375,
      "step": 250
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.014303597621619701,
      "learning_rate": 4.757748865501322e-06,
      "logits/chosen": -4.788120269775391,
      "logits/rejected": -5.2924675941467285,
      "logps/chosen": -345.41339111328125,
      "logps/rejected": -90.44126892089844,
      "loss": 0.0215,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 19.33420181274414,
      "rewards/margins": 17.74561882019043,
      "rewards/rejected": 1.588582992553711,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.03270456939935684,
      "learning_rate": 4.59559007199896e-06,
      "logits/chosen": -4.678920745849609,
      "logits/rejected": -5.259213447570801,
      "logps/chosen": -277.60382080078125,
      "logps/rejected": -92.67758178710938,
      "loss": 0.034,
      "rewards/accuracies": 0.9874999523162842,
      "rewards/chosen": 18.288726806640625,
      "rewards/margins": 16.709794998168945,
      "rewards/rejected": 1.5789320468902588,
      "step": 350
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.23847262561321259,
      "learning_rate": 4.396476391236707e-06,
      "logits/chosen": -4.641234397888184,
      "logits/rejected": -5.171990394592285,
      "logps/chosen": -278.0753173828125,
      "logps/rejected": -96.62535095214844,
      "loss": 0.0097,
      "rewards/accuracies": 0.9975000023841858,
      "rewards/chosen": 18.73511505126953,
      "rewards/margins": 17.584579467773438,
      "rewards/rejected": 1.1505377292633057,
      "step": 400
    },
    {
      "epoch": 1.0274285714285714,
      "grad_norm": 0.04138445481657982,
      "learning_rate": 4.16391911281399e-06,
      "logits/chosen": -4.704158782958984,
      "logits/rejected": -5.183492660522461,
      "logps/chosen": -251.24853515625,
      "logps/rejected": -100.64278411865234,
      "loss": 0.0218,
      "rewards/accuracies": 0.9949495196342468,
      "rewards/chosen": 16.326374053955078,
      "rewards/margins": 15.379735946655273,
      "rewards/rejected": 0.9466387629508972,
      "step": 450
    },
    {
      "epoch": 1.1417142857142857,
      "grad_norm": 1.1911537001196848e-07,
      "learning_rate": 3.90201929071098e-06,
      "logits/chosen": -4.680719375610352,
      "logits/rejected": -5.179136753082275,
      "logps/chosen": -319.30322265625,
      "logps/rejected": -95.86102294921875,
      "loss": 0.0131,
      "rewards/accuracies": 0.9950000047683716,
      "rewards/chosen": 18.473247528076172,
      "rewards/margins": 17.653919219970703,
      "rewards/rejected": 0.8193295001983643,
      "step": 500
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.021495435386896133,
      "learning_rate": 3.6153954228526893e-06,
      "logits/chosen": -4.636545181274414,
      "logits/rejected": -5.217836380004883,
      "logps/chosen": -301.7703857421875,
      "logps/rejected": -100.3604965209961,
      "loss": 0.0089,
      "rewards/accuracies": 0.9975000023841858,
      "rewards/chosen": 18.31177520751953,
      "rewards/margins": 17.495891571044922,
      "rewards/rejected": 0.8158830404281616,
      "step": 550
    },
    {
      "epoch": 1.3702857142857143,
      "grad_norm": 0.03291226178407669,
      "learning_rate": 3.3091020057574137e-06,
      "logits/chosen": -4.64285945892334,
      "logits/rejected": -5.1779375076293945,
      "logps/chosen": -334.06781005859375,
      "logps/rejected": -98.57836151123047,
      "loss": 0.0131,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 19.685211181640625,
      "rewards/margins": 18.85162353515625,
      "rewards/rejected": 0.833588719367981,
      "step": 600
    },
    {
      "epoch": 1.4845714285714287,
      "grad_norm": 0.015391036868095398,
      "learning_rate": 2.988540400525517e-06,
      "logits/chosen": -4.654729843139648,
      "logits/rejected": -5.20307731628418,
      "logps/chosen": -287.774658203125,
      "logps/rejected": -101.26809692382812,
      "loss": 0.0148,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 17.304004669189453,
      "rewards/margins": 16.868732452392578,
      "rewards/rejected": 0.4352688789367676,
      "step": 650
    },
    {
      "epoch": 1.5988571428571428,
      "grad_norm": 0.028175724670290947,
      "learning_rate": 2.659363582010948e-06,
      "logits/chosen": -4.615201950073242,
      "logits/rejected": -5.1778154373168945,
      "logps/chosen": -301.61920166015625,
      "logps/rejected": -104.07254028320312,
      "loss": 0.0157,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 17.809852600097656,
      "rewards/margins": 17.46963119506836,
      "rewards/rejected": 0.34021902084350586,
      "step": 700
    },
    {
      "epoch": 1.713142857142857,
      "grad_norm": 0.0023251541424542665,
      "learning_rate": 2.3273764508855114e-06,
      "logits/chosen": -4.615557670593262,
      "logits/rejected": -5.157452583312988,
      "logps/chosen": -299.1310729980469,
      "logps/rejected": -107.46631622314453,
      "loss": 0.0147,
      "rewards/accuracies": 0.9950000047683716,
      "rewards/chosen": 17.90169906616211,
      "rewards/margins": 17.784608840942383,
      "rewards/rejected": 0.11709024012088776,
      "step": 750
    },
    {
      "epoch": 1.8274285714285714,
      "grad_norm": 0.8610329031944275,
      "learning_rate": 1.998433466552507e-06,
      "logits/chosen": -4.578699111938477,
      "logits/rejected": -5.091855525970459,
      "logps/chosen": -323.3194580078125,
      "logps/rejected": -105.86788940429688,
      "loss": 0.0271,
      "rewards/accuracies": 0.9874999523162842,
      "rewards/chosen": 18.206283569335938,
      "rewards/margins": 18.005207061767578,
      "rewards/rejected": 0.20107583701610565,
      "step": 800
    },
    {
      "epoch": 1.9417142857142857,
      "grad_norm": 0.0140400854870677,
      "learning_rate": 1.6783354061120876e-06,
      "logits/chosen": -4.602456092834473,
      "logits/rejected": -5.116126537322998,
      "logps/chosen": -276.7126770019531,
      "logps/rejected": -107.22685241699219,
      "loss": 0.0082,
      "rewards/accuracies": 0.9975000023841858,
      "rewards/chosen": 16.94664764404297,
      "rewards/margins": 17.0887451171875,
      "rewards/rejected": -0.14209935069084167,
      "step": 850
    },
    {
      "epoch": 2.0548571428571427,
      "grad_norm": 7.284585535671795e-06,
      "learning_rate": 1.3727270699924205e-06,
      "logits/chosen": -4.63324499130249,
      "logits/rejected": -5.140608787536621,
      "logps/chosen": -328.6706848144531,
      "logps/rejected": -109.06896209716797,
      "loss": 0.0125,
      "rewards/accuracies": 0.9949495196342468,
      "rewards/chosen": 18.646038055419922,
      "rewards/margins": 18.589553833007812,
      "rewards/rejected": 0.05648339167237282,
      "step": 900
    },
    {
      "epoch": 2.169142857142857,
      "grad_norm": 0.013642189092934132,
      "learning_rate": 1.0869977381666694e-06,
      "logits/chosen": -4.619718074798584,
      "logits/rejected": -5.1501617431640625,
      "logps/chosen": -317.5562744140625,
      "logps/rejected": -103.42344665527344,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 17.806419372558594,
      "rewards/margins": 17.738204956054688,
      "rewards/rejected": 0.06821377575397491,
      "step": 950
    },
    {
      "epoch": 2.2834285714285714,
      "grad_norm": 0.0003793967771343887,
      "learning_rate": 8.261861323703287e-07,
      "logits/chosen": -4.620936393737793,
      "logits/rejected": -5.165548324584961,
      "logps/chosen": -300.62432861328125,
      "logps/rejected": -105.94694519042969,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 18.005443572998047,
      "rewards/margins": 17.667255401611328,
      "rewards/rejected": 0.3381858170032501,
      "step": 1000
    },
    {
      "epoch": 2.3977142857142857,
      "grad_norm": 0.001340059912763536,
      "learning_rate": 5.948915602719435e-07,
      "logits/chosen": -4.61100959777832,
      "logits/rejected": -5.112129211425781,
      "logps/chosen": -265.16607666015625,
      "logps/rejected": -106.93788146972656,
      "loss": 0.0187,
      "rewards/accuracies": 0.9924999475479126,
      "rewards/chosen": 16.780975341796875,
      "rewards/margins": 16.852149963378906,
      "rewards/rejected": -0.07117524743080139,
      "step": 1050
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.2248021513223648,
      "learning_rate": 3.9719280853400736e-07,
      "logits/chosen": -4.616926193237305,
      "logits/rejected": -5.146554946899414,
      "logps/chosen": -343.23797607421875,
      "logps/rejected": -104.11863708496094,
      "loss": 0.0156,
      "rewards/accuracies": 0.9900000095367432,
      "rewards/chosen": 18.582801818847656,
      "rewards/margins": 18.370628356933594,
      "rewards/rejected": 0.21217235922813416,
      "step": 1100
    },
    {
      "epoch": 2.6262857142857143,
      "grad_norm": 0.0013330465881153941,
      "learning_rate": 2.3657621505223578e-07,
      "logits/chosen": -4.544235706329346,
      "logits/rejected": -5.085517883300781,
      "logps/chosen": -263.21636962890625,
      "logps/rejected": -113.38766479492188,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 17.189720153808594,
      "rewards/margins": 17.497356414794922,
      "rewards/rejected": -0.30763763189315796,
      "step": 1150
    },
    {
      "epoch": 2.7405714285714287,
      "grad_norm": 0.06493645906448364,
      "learning_rate": 1.1587418879033557e-07,
      "logits/chosen": -4.576766014099121,
      "logits/rejected": -5.118627548217773,
      "logps/chosen": -281.36309814453125,
      "logps/rejected": -108.79395294189453,
      "loss": 0.0076,
      "rewards/accuracies": 0.9975000023841858,
      "rewards/chosen": 17.563236236572266,
      "rewards/margins": 17.698881149291992,
      "rewards/rejected": -0.13564495742321014,
      "step": 1200
    },
    {
      "epoch": 2.854857142857143,
      "grad_norm": 0.0033179183956235647,
      "learning_rate": 3.721526138822595e-08,
      "logits/chosen": -4.546469211578369,
      "logits/rejected": -5.097599506378174,
      "logps/chosen": -321.63909912109375,
      "logps/rejected": -103.37835693359375,
      "loss": 0.007,
      "rewards/accuracies": 0.9975000023841858,
      "rewards/chosen": 18.270339965820312,
      "rewards/margins": 18.35964012145996,
      "rewards/rejected": -0.08929897844791412,
      "step": 1250
    },
    {
      "epoch": 2.9691428571428573,
      "grad_norm": 0.001648034667596221,
      "learning_rate": 1.9865513634884094e-09,
      "logits/chosen": -4.593493461608887,
      "logits/rejected": -5.1307477951049805,
      "logps/chosen": -301.1629638671875,
      "logps/rejected": -107.4086685180664,
      "loss": 0.0122,
      "rewards/accuracies": 0.9950000047683716,
      "rewards/chosen": 17.946300506591797,
      "rewards/margins": 18.190933227539062,
      "rewards/rejected": -0.2446337640285492,
      "step": 1300
    },
    {
      "epoch": 3.0,
      "step": 1314,
      "total_flos": 1.4336516947968e+17,
      "train_loss": 0.0258609245402265,
      "train_runtime": 2037.7556,
      "train_samples_per_second": 5.153,
      "train_steps_per_second": 0.645
    }
  ],
  "logging_steps": 50,
  "max_steps": 1314,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4336516947968e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
